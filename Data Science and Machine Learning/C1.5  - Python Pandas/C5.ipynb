{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae3c0ad",
   "metadata": {},
   "source": [
    "1. Create a data frame storing student's Roll number, Name, Total Marks and Class. Sort the data frame using Name and Marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c859e257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Roll number     Name  Total Marks  Class\n",
      "0          101    Alice           85     10\n",
      "1          102      Bob           92     11\n",
      "2          103  Charlie           78     10\n",
      "3          104    David           95     12\n",
      "4          105      Eve           88     11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Roll number': [101, 102, 103, 104, 105],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Total Marks': [85, 92, 78, 95, 88],\n",
    "    'Class': [10, 11, 10, 12, 11]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort DataFrame by Name and Total Marks\n",
    "df_sorted = df.sort_values(by=['Name', 'Total Marks'])\n",
    "\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a97e6526",
   "metadata": {},
   "source": [
    "Just replace the sample data with your actual student data. This code will create a DataFrame, sort it first by Name in alphabetical order and then by Total Marks in ascending order. The result will be the sorted DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a240368",
   "metadata": {},
   "source": [
    "2. Use pivot operation to reshape the above data frame using Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62346558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class          10    11    12\n",
      "Roll number                  \n",
      "101          85.0   NaN   NaN\n",
      "102           NaN  92.0   NaN\n",
      "103          78.0   NaN   NaN\n",
      "104           NaN   NaN  95.0\n",
      "105           NaN  88.0   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Roll number': [101, 102, 103, 104, 105],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Total Marks': [85, 92, 78, 95, 88],\n",
    "    'Class': [10, 11, 10, 12, 11]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Reshape using pivot_table\n",
    "pivot_df = pd.pivot_table(df, values='Total Marks', index='Roll number', columns='Class', aggfunc='sum')\n",
    "\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "124681be",
   "metadata": {},
   "source": [
    "In this code, the pivot_table function reshapes the DataFrame using the 'Roll number' as the index, 'Class' as the columns, and 'Total Marks' as the values. The aggfunc parameter specifies how to aggregate the values (in this case, we are using 'sum' to aggregate the total marks of students in each class). The resulting DataFrame will have 'Roll number' as the index, 'Class' as the columns, and the aggregated total marks as the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06d7cb",
   "metadata": {},
   "source": [
    "3. Write a program to count the number of null values in a series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d887e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = [10, 20, None, 30, None, 40, 50, None, 60]\n",
    "\n",
    "# Create a Series object\n",
    "series = pd.Series(data)\n",
    "\n",
    "# Count the number of null values\n",
    "null_count = series.isnull().sum()\n",
    "\n",
    "print(\"Number of null values:\", null_count)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20c6eab6",
   "metadata": {},
   "source": [
    "In this program, we first create a Series object named series with some sample data, including some None values. We then use the isnull() function to create a boolean Series that indicates whether each element is null or not. The sum() function is then used on the boolean Series to count the number of True values, which represent null values. Finally, we print the count of null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2c3a4",
   "metadata": {},
   "source": [
    "4. Create a data frame with three columns Name, Age and Rating\n",
    "* Find the sum of the columns\n",
    "* Find average age and rating\n",
    "* Find the standard deviation\n",
    "* Describe the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc4cf577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of columns:\n",
      "Name      AliceBobCharlieDavidEve\n",
      "Age                           137\n",
      "Rating                       20.2\n",
      "dtype: object\n",
      "\n",
      "Average Age: 27.4\n",
      "Average Rating: 4.04\n",
      "\n",
      "Standard Deviation of Age: 3.9749213828703582\n",
      "Standard Deviation of Rating: 0.3209361307176243\n",
      "\n",
      "DataFrame Description:\n",
      "             Age    Rating\n",
      "count   5.000000  5.000000\n",
      "mean   27.400000  4.040000\n",
      "std     3.974921  0.320936\n",
      "min    22.000000  3.700000\n",
      "25%    25.000000  3.800000\n",
      "50%    28.000000  4.000000\n",
      "75%    30.000000  4.200000\n",
      "max    32.000000  4.500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, 32, 28, 22, 30],\n",
    "    'Rating': [4.5, 3.8, 4.2, 4.0, 3.7]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sum of columns\n",
    "sum_of_columns = df.sum()\n",
    "\n",
    "# Average age and rating\n",
    "average_age = df['Age'].mean()\n",
    "average_rating = df['Rating'].mean()\n",
    "\n",
    "# Standard deviation\n",
    "std_deviation_age = df['Age'].std()\n",
    "std_deviation_rating = df['Rating'].std()\n",
    "\n",
    "# Describe the DataFrame\n",
    "df_description = df.describe()\n",
    "\n",
    "print(\"Sum of columns:\")\n",
    "print(sum_of_columns)\n",
    "print(\"\\nAverage Age:\", average_age)\n",
    "print(\"Average Rating:\", average_rating)\n",
    "print(\"\\nStandard Deviation of Age:\", std_deviation_age)\n",
    "print(\"Standard Deviation of Rating:\", std_deviation_rating)\n",
    "print(\"\\nDataFrame Description:\")\n",
    "print(df_description)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04334528",
   "metadata": {},
   "source": [
    "This program creates a DataFrame with three columns (Name, Age, and Rating), calculates the sum of columns, average age and rating, standard deviations, and provides a description of the DataFrame using the describe() function. Just replace the sample data with your actual data if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a941be6",
   "metadata": {},
   "source": [
    "5. Create a data frame with three columns and 5 rows of random values. Find the row-wise sum using the apply() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2d384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column1  Column2  Column3  RowSum\n",
      "0        7       10        4      21\n",
      "1        4        3        8      15\n",
      "2        8        7        8      23\n",
      "3        5        8        3      16\n",
      "4        7        5        6      18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with random values\n",
    "np.random.seed(42)  # For reproducibility\n",
    "data = {\n",
    "    'Column1': np.random.randint(1, 11, 5),\n",
    "    'Column2': np.random.randint(1, 11, 5),\n",
    "    'Column3': np.random.randint(1, 11, 5)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a function to calculate row-wise sum\n",
    "def row_sum(row):\n",
    "    return row.sum()\n",
    "\n",
    "# Calculate row-wise sum using apply() function\n",
    "row_sums = df.apply(row_sum, axis=1)\n",
    "\n",
    "# Add row-wise sum as a new column\n",
    "df['RowSum'] = row_sums\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a118fad",
   "metadata": {},
   "source": [
    "In this program, we first create a DataFrame with three columns and five rows of random integer values between 1 and 10. Then, we define a function row_sum() that takes a row and returns the sum of its values. We use the apply() function along with axis=1 to apply the row_sum() function to each row of the DataFrame, resulting in a Series containing the row-wise sums. Finally, we add this Series as a new column named 'RowSum' to the DataFrame and print the updated DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b167f8e",
   "metadata": {},
   "source": [
    "6. Create a data frame recording marks in Physics and Chemistry class tests. Find out at what point or below 100%(1), 95%(.95), and 50%(.5) of the scores are lying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d86dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics:\n",
      "100% or below: 0.1176\n",
      "95.0% or below: 0.1159\n",
      "50.0% or below: 0.1021\n",
      "\n",
      "Chemistry:\n",
      "100% or below: 0.1245\n",
      "95.0% or below: 0.1204\n",
      "50.0% or below: 0.1003\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Physics': [85, 92, 78, 95, 88, 72, 90, 60, 68, 80],\n",
    "    'Chemistry': [75, 88, 62, 80, 95, 70, 85, 58, 72, 78]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate cumulative distribution for each subject\n",
    "cumulative_dist_physics = np.sort(df['Physics']) / np.sum(df['Physics'])\n",
    "cumulative_dist_chemistry = np.sort(df['Chemistry']) / np.sum(df['Chemistry'])\n",
    "\n",
    "# Find points for specific percentiles\n",
    "percentiles = [1, 0.95, 0.5]  # 100%, 95%, and 50%\n",
    "\n",
    "points_physics = [np.percentile(cumulative_dist_physics, p * 100) for p in percentiles]\n",
    "points_chemistry = [np.percentile(cumulative_dist_chemistry, p * 100) for p in percentiles]\n",
    "\n",
    "print(\"Physics:\")\n",
    "for p, point in zip(percentiles, points_physics):\n",
    "    print(f\"{p*100}% or below: {point:.4f}\")\n",
    "\n",
    "print(\"\\nChemistry:\")\n",
    "for p, point in zip(percentiles, points_chemistry):\n",
    "    print(f\"{p*100}% or below: {point:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee9fd5f4",
   "metadata": {},
   "source": [
    "In this program, we first create a DataFrame with scores in Physics and Chemistry class tests. We then calculate the cumulative distribution by sorting the scores and dividing them by the sum of scores. After that, we use the np.percentile() function to find the points at which the specified percentiles (100%, 95%, and 50%) or below are lying in the cumulative distribution. Finally, we print these points for both Physics and Chemistry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c817d",
   "metadata": {},
   "source": [
    "#7. Consider the following data frame and illustrate application aggregate functions both row-wise and column wise.\n",
    "#A B C\n",
    "#1.0 2 3.0\n",
    "#4.0 5 6.0\n",
    "#7.0 8 9.0\n",
    "#NaN NaN NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea45c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Consider the following data frame and illustrate application aggregate functions both row-wise and column wise.\n",
    "#A B C\n",
    "#1.0 2 3.0\n",
    "#4.0 5 6.0\n",
    "#7.0 8 9.0\n",
    "#NaN NaN NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546c144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-wise aggregate functions:\n",
      "Sum of each row:\n",
      "0     6.0\n",
      "1    15.0\n",
      "2    24.0\n",
      "3     0.0\n",
      "dtype: float64\n",
      "\n",
      "Mean of each row:\n",
      "0    2.0\n",
      "1    5.0\n",
      "2    8.0\n",
      "3    NaN\n",
      "dtype: float64\n",
      "\n",
      "Max of each row:\n",
      "0    3.0\n",
      "1    6.0\n",
      "2    9.0\n",
      "3    NaN\n",
      "dtype: float64\n",
      "\n",
      "Column-wise aggregate functions:\n",
      "Sum of each column:\n",
      "A    12.0\n",
      "B    15.0\n",
      "C    18.0\n",
      "dtype: float64\n",
      "\n",
      "Mean of each column:\n",
      "A    4.0\n",
      "B    5.0\n",
      "C    6.0\n",
      "dtype: float64\n",
      "\n",
      "Max of each column:\n",
      "A    7.0\n",
      "B    8.0\n",
      "C    9.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    'A': [1.0, 4.0, 7.0, np.nan],\n",
    "    'B': [2, 5, 8, np.nan],\n",
    "    'C': [3.0, 6.0, 9.0, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Row-wise aggregate functions\n",
    "row_sums = df.apply(np.sum, axis=1)\n",
    "row_means = df.apply(np.mean, axis=1)\n",
    "row_maxs = df.apply(np.max, axis=1)\n",
    "\n",
    "# Column-wise aggregate functions\n",
    "col_sums = df.apply(np.sum, axis=0)\n",
    "col_means = df.apply(np.mean, axis=0)\n",
    "col_maxs = df.apply(np.max, axis=0)\n",
    "\n",
    "print(\"Row-wise aggregate functions:\")\n",
    "print(\"Sum of each row:\")\n",
    "print(row_sums)\n",
    "print(\"\\nMean of each row:\")\n",
    "print(row_means)\n",
    "print(\"\\nMax of each row:\")\n",
    "print(row_maxs)\n",
    "\n",
    "print(\"\\nColumn-wise aggregate functions:\")\n",
    "print(\"Sum of each column:\")\n",
    "print(col_sums)\n",
    "print(\"\\nMean of each column:\")\n",
    "print(col_means)\n",
    "print(\"\\nMax of each column:\")\n",
    "print(col_maxs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3978e893",
   "metadata": {},
   "source": [
    "In this program, we create the DataFrame based on the provided data. Then we use the apply() function to apply the aggregate functions (np.sum, np.mean, and np.max) both row-wise (axis=1) and column-wise (axis=0). The results are printed to show the calculated sums, means, and max values for each row and each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98542c57",
   "metadata": {},
   "source": [
    "8. Download phon.csv form http://python-ds.com/download-aggregation-csv-data and write code to find:\n",
    "* How many rows are there in the dataset.\n",
    "* What was the longest phone call / data entry?\n",
    "* How many seconds of phone calls recorded in total?\n",
    "* Number of nonnull unique network entries.\n",
    "* How many entries are there for each month?\n",
    "* Get the first entry for each month\n",
    "* Get the sum of the durations per month\n",
    "* Get the number of dates/entries in each month\n",
    "* Sum of durations, for calls only, to each network\n",
    "* How many calls, sms, and data entries are in each month?\n",
    "* How many calls. texts. and data are sent per month, split by network type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0039742",
   "metadata": {},
   "source": [
    "9. Consider the table that describes a dataset about a department store. Write the code to know what is the mean purchase amount of each user. The desired output should be "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e350d161",
   "metadata": {},
   "source": [
    "10. Create a data frame with any values of your choice. Reindex the data frame rows and fill the missing values with value 100. Reindex the data frame columns and fill the missing values with value 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24cd764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "1  2.0  NaN  10\n",
      "2  NaN  7.0  11\n",
      "3  4.0  8.0  12\n",
      "\n",
      "DataFrame with Reindexed Rows and Filled Missing Values:\n",
      "          A      B    C\n",
      "row1  100.0  100.0  100\n",
      "row2  100.0  100.0  100\n",
      "row3  100.0  100.0  100\n",
      "row4  100.0  100.0  100\n",
      "\n",
      "DataFrame with Reindexed Columns and Filled Missing Values:\n",
      "      col1  col2  col3\n",
      "row1    25    25    25\n",
      "row2    25    25    25\n",
      "row3    25    25    25\n",
      "row4    25    25    25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [5, np.nan, 7, 8],\n",
    "    'C': [9, 10, 11, 12]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Reindex rows and fill missing values with 100\n",
    "new_index = ['row1', 'row2', 'row3', 'row4']\n",
    "df_reindexed_rows = df.reindex(new_index, fill_value=100)\n",
    "\n",
    "# Reindex columns and fill missing values with 25\n",
    "new_columns = ['col1', 'col2', 'col3']\n",
    "df_reindexed_columns = df_reindexed_rows.reindex(columns=new_columns, fill_value=25)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame with Reindexed Rows and Filled Missing Values:\")\n",
    "print(df_reindexed_rows)\n",
    "print(\"\\nDataFrame with Reindexed Columns and Filled Missing Values:\")\n",
    "print(df_reindexed_columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a609a43",
   "metadata": {},
   "source": [
    "In this example, we first create a DataFrame with some sample data. Then, we reindex the rows using the reindex() function and specify the new index (new_index) along with the value to fill missing values (100). After that, we reindex the columns using the reindex() function again, this time specifying the new columns (new_columns) and the value to fill missing values (25). Finally, we print the original DataFrame, the DataFrame with reindexed rows, and the DataFrame with reindexed columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb6f4a",
   "metadata": {},
   "source": [
    "11. Download the gapminder data from URL \"http://bi.ly/2cLzoxH.\" Print the names of the columns. Rename the column labels using both the ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce16e8a6",
   "metadata": {},
   "source": [
    "12. Create a data frame with columns country, year and reports. Demonstrate changing the rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c07318da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  country  year  reports\n",
      "0     USA  2019      100\n",
      "1  Canada  2019      150\n",
      "2  Mexico  2019       80\n",
      "3     USA  2020      120\n",
      "4  Canada  2020      200\n",
      "\n",
      "Modified DataFrame:\n",
      "   country  year  reports\n",
      "0   France  2022       60\n",
      "1   Canada  2020      160\n",
      "2   Mexico  2020       90\n",
      "3  Germany  2022       85\n",
      "4   Canada  2021      210\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'country': ['USA', 'Canada', 'Mexico', 'USA', 'Canada'],\n",
    "    'year': [2019, 2019, 2019, 2020, 2020],\n",
    "    'reports': [100, 150, 80, 120, 200]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Changing rows using indexing\n",
    "df.loc[0] = ['France', 2021, 50]\n",
    "df.loc[3] = ['Germany', 2021, 75]\n",
    "\n",
    "# Changing columns using indexing\n",
    "df['reports'] = df['reports'] + 10\n",
    "df['year'] = df['year'] + 1\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(\"\\nModified DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e5a9506",
   "metadata": {},
   "source": [
    "In this example, we first create a DataFrame with columns 'country', 'year', and 'reports'. Then we demonstrate changing rows and columns:\n",
    "\n",
    "1. We change rows using the .loc[] indexer. We replace the first row with new data for 'France' and 2021, and the fourth row with data for 'Germany' and 2021.\n",
    "\n",
    "2. We change columns using column indexing. We add 10 to all 'reports' values using df['reports'] = df['reports'] + 10, and we increment all 'year' values by 1 using df['year'] = df['year'] + 1.\n",
    "\n",
    "The output will show you the original DataFrame and the modified DataFrame after making the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f66e53",
   "metadata": {},
   "source": [
    "13. Create a data frame with a column Gender having values \"m\" and \"f\" and a column Height. Find average height of both males and females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14316e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Height of Males: 177.5\n",
      "Average Height of Females: 161.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Gender': ['m', 'f', 'm', 'f', 'm', 'f', 'm', 'f'],\n",
    "    'Height': [175, 162, 180, 155, 170, 168, 185, 160]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate average height for males and females\n",
    "average_height_males = df[df['Gender'] == 'm']['Height'].mean()\n",
    "average_height_females = df[df['Gender'] == 'f']['Height'].mean()\n",
    "\n",
    "print(\"Average Height of Males:\", average_height_males)\n",
    "print(\"Average Height of Females:\", average_height_females)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0cc84f2c",
   "metadata": {},
   "source": [
    "In this example, we first create a DataFrame with a 'Gender' column and a 'Height' column, containing sample data. We then calculate the average height for males (where 'Gender' is 'm') and for females (where 'Gender' is 'f') using the mean() function on the 'Height' column for the respective groups. Finally, we print out the average heights for both males and females."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc68bb",
   "metadata": {},
   "source": [
    "14. Create a data frame with name, age and marks.\n",
    "* Group the data by a column and return the mean age per group\n",
    "* Capitalizes all the column headers\n",
    "* Create a pipeline that applies the mean_age_by_group function and then applies the uppercase column name function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6c8a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Mean Age:\n",
      "marks\n",
      "78    28.0\n",
      "85    25.0\n",
      "88    30.0\n",
      "90    29.0\n",
      "92    32.0\n",
      "95    22.0\n",
      "dtype: float64\n",
      "\n",
      "Pipeline Result:\n",
      "   Marks   NaN\n",
      "0     78  28.0\n",
      "1     85  25.0\n",
      "2     88  30.0\n",
      "3     90  29.0\n",
      "4     92  32.0\n",
      "5     95  22.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Fiona'],\n",
    "    'age': [25, 32, 28, 22, 30, 29],\n",
    "    'marks': [85, 92, 78, 95, 88, 90]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate mean age per group\n",
    "def mean_age_by_group(group):\n",
    "    return group['age'].mean()\n",
    "\n",
    "# Function to capitalize column headers\n",
    "def capitalize_column_headers(df):\n",
    "    df.columns = df.columns.str.capitalize()\n",
    "    return df\n",
    "\n",
    "# Group by 'marks' column and calculate mean age\n",
    "grouped_mean_age = df.groupby('marks').apply(mean_age_by_group)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = (df.groupby('marks')\n",
    "            .apply(mean_age_by_group)\n",
    "            .reset_index()\n",
    "            .pipe(capitalize_column_headers))\n",
    "\n",
    "print(\"Grouped Mean Age:\")\n",
    "print(grouped_mean_age)\n",
    "print(\"\\nPipeline Result:\")\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fc956fd",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "1. We first create a DataFrame with columns 'name', 'age', and 'marks'.\n",
    "2. We define the function mean_age_by_group() which calculates the mean age for each group based on the 'marks' column.\n",
    "3. We define the function capitalize_column_headers() to capitalize the column headers of a DataFrame.\n",
    "4. We use the groupby() function to group the data by the 'marks' column and apply the mean_age_by_group() function.\n",
    "5. We create a pipeline using the pipe() function, where we first calculate the mean age using the mean_age_by_group() function, then reset the index, and finally apply the capitalize_column_headers() function.\n",
    "The output will show the calculated mean age per group and the result of the pipeline with capitalized column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19049be",
   "metadata": {},
   "source": [
    "15. Create a data frame containing 10 rows and 4 columns of random values.\n",
    "* Use date values in gaps of 10 to specify the index of the data frame.\n",
    "* Apply sum on the data frame\n",
    "* Find mean of first column\n",
    "* Find minimum values of last two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "911549b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "            Column1  Column2  Column3  Column4\n",
      "2023-01-01       52       93       15       72\n",
      "2023-01-11       61       21       83       87\n",
      "2023-01-21       75       75       88      100\n",
      "2023-01-31       24        3       22       53\n",
      "2023-02-10        2       88       30       38\n",
      "2023-02-20        2       64       60       21\n",
      "2023-03-02       33       76       58       22\n",
      "2023-03-12       89       49       91       59\n",
      "2023-03-22       42       92       60       80\n",
      "2023-04-01       15       62       62       47\n",
      "\n",
      "Sum of the DataFrame:\n",
      "Column1    395\n",
      "Column2    623\n",
      "Column3    569\n",
      "Column4    579\n",
      "dtype: int64\n",
      "\n",
      "Mean of the First Column:\n",
      "39.5\n",
      "\n",
      "Minimum Values of Last Two Columns:\n",
      "Minimum of Column3: 15\n",
      "Minimum of Column4: 21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(42)\n",
    "data = np.random.randint(1, 101, size=(10, 4))\n",
    "\n",
    "# Generate date index\n",
    "date_index = pd.date_range(start='2023-01-01', periods=10, freq='10D')\n",
    "\n",
    "# Create DataFrame with date index\n",
    "df = pd.DataFrame(data, index=date_index, columns=['Column1', 'Column2', 'Column3', 'Column4'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Calculate sum of the DataFrame\n",
    "df_sum = df.sum()\n",
    "\n",
    "# Calculate mean of the first column\n",
    "mean_column1 = df['Column1'].mean()\n",
    "\n",
    "# Calculate minimum values of last two columns\n",
    "min_column3 = df['Column3'].min()\n",
    "min_column4 = df['Column4'].min()\n",
    "\n",
    "print(\"\\nSum of the DataFrame:\")\n",
    "print(df_sum)\n",
    "print(\"\\nMean of the First Column:\")\n",
    "print(mean_column1)\n",
    "print(\"\\nMinimum Values of Last Two Columns:\")\n",
    "print(\"Minimum of Column3:\", min_column3)\n",
    "print(\"Minimum of Column4:\", min_column4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f86b4ed",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "1. We generate random data using np.random.randint().\n",
    "2. We use the pd.date_range() function to create a date index with a frequency of 10 days.\n",
    "3. We create the DataFrame using the generated random data and the date index.\n",
    "4. We calculate the sum of the DataFrame using the sum() function.\n",
    "5. We calculate the mean of the first column using indexing and the mean() function.\n",
    "6. We calculate the minimum values of the last two columns using indexing and the min() function.\n",
    "The output will show the created DataFrame, the sum of the DataFrame, the mean of the first column, and the minimum values of the last two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81200e51",
   "metadata": {},
   "source": [
    "16. Download user_device and user_usage from GitHub and demonstrate the merge() operation on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a9df93",
   "metadata": {},
   "source": [
    "17. Write a program that concatenates two data frames storing informatiob about students along column axis and a continuous index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3240b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame:\n",
      "   Roll Number     Name  Age  Roll Number   Name  Age\n",
      "0          101    Alice   20          104  David   22\n",
      "1          102      Bob   21          105    Eve   20\n",
      "2          103  Charlie   19          106  Fiona   23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for data frames\n",
    "data1 = {'Roll Number': [101, 102, 103],\n",
    "         'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "         'Age': [20, 21, 19]}\n",
    "\n",
    "data2 = {'Roll Number': [104, 105, 106],\n",
    "         'Name': ['David', 'Eve', 'Fiona'],\n",
    "         'Age': [22, 20, 23]}\n",
    "\n",
    "# Create data frames\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Concatenate data frames along column axis\n",
    "concatenated_df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "print(\"Concatenated DataFrame:\")\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e84253b6",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "1. We create two data frames (df1 and df2) with student information.\n",
    "2. We use the pd.concat() function to concatenate the data frames along the column axis (axis=1).\n",
    "3. The continuous index will be assigned automatically.\n",
    "The output will display the concatenated DataFrame with student information along the column axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd97eaf",
   "metadata": {},
   "source": [
    "18. Write a program to concatenate three data frames and append two data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1812a3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame (Vertical):\n",
      "    A   B\n",
      "0   1   4\n",
      "1   2   5\n",
      "2   3   6\n",
      "3   7  10\n",
      "4   8  11\n",
      "5   9  12\n",
      "6  13  16\n",
      "7  14  17\n",
      "8  15  18\n",
      "\n",
      "Concatenated DataFrame (Horizontal):\n",
      "   A  B  A   B   A   B\n",
      "0  1  4  7  10  13  16\n",
      "1  2  5  8  11  14  17\n",
      "2  3  6  9  12  15  18\n",
      "\n",
      "Appended DataFrame:\n",
      "    A   B\n",
      "0   1   4\n",
      "1   2   5\n",
      "2   3   6\n",
      "3  19  22\n",
      "4  20  23\n",
      "5  21  24\n",
      "6  13  16\n",
      "7  14  17\n",
      "8  15  18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for data frames\n",
    "data1 = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "data2 = {'A': [7, 8, 9], 'B': [10, 11, 12]}\n",
    "data3 = {'A': [13, 14, 15], 'B': [16, 17, 18]}\n",
    "data4 = {'A': [19, 20, 21], 'B': [22, 23, 24]}\n",
    "\n",
    "# Create data frames\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "df3 = pd.DataFrame(data3)\n",
    "df4 = pd.DataFrame(data4)\n",
    "\n",
    "# Concatenate data frames vertically\n",
    "concatenated_df_vertical = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Concatenate data frames horizontally\n",
    "concatenated_df_horizontal = pd.concat([df1, df2, df3], axis=1)\n",
    "\n",
    "# Append data frames using concat\n",
    "appended_df = pd.concat([df1, df4, df3], ignore_index=True)\n",
    "\n",
    "print(\"Concatenated DataFrame (Vertical):\")\n",
    "print(concatenated_df_vertical)\n",
    "\n",
    "print(\"\\nConcatenated DataFrame (Horizontal):\")\n",
    "print(concatenated_df_horizontal)\n",
    "\n",
    "print(\"\\nAppended DataFrame:\")\n",
    "print(appended_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48cd497f",
   "metadata": {},
   "source": [
    "I appreciate your patience, and I apologize for any confusion caused by the previous response. This corrected code should work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba97a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
